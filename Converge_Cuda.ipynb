{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "10240436-e3f8-4ef0-8c19-b654e5f34601",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA is available! Using GPU.\n",
      "Number of CUDA devices: 4\n",
      "CUDA device name: NVIDIA A10G\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'numpy.ndarray' object has no attribute 'to'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 35\u001b[0m\n\u001b[1;32m     32\u001b[0m csv_file \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m./MEFAR_MID.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     33\u001b[0m dataset \u001b[38;5;241m=\u001b[39m CustomDataset(csv_file)\n\u001b[0;32m---> 35\u001b[0m train_set, test_set \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_test_split\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m42\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     37\u001b[0m train_loader \u001b[38;5;241m=\u001b[39m DataLoader(train_set, batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m, shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     38\u001b[0m test_loader \u001b[38;5;241m=\u001b[39m DataLoader(test_set, batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[0;32m~/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/sklearn/utils/_param_validation.py:213\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    207\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    208\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m    209\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m    210\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m    211\u001b[0m         )\n\u001b[1;32m    212\u001b[0m     ):\n\u001b[0;32m--> 213\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    214\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    215\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[1;32m    217\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[1;32m    218\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[1;32m    219\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[1;32m    220\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    221\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    222\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[1;32m    223\u001b[0m     )\n",
      "File \u001b[0;32m~/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/sklearn/model_selection/_split.py:2683\u001b[0m, in \u001b[0;36mtrain_test_split\u001b[0;34m(test_size, train_size, random_state, shuffle, stratify, *arrays)\u001b[0m\n\u001b[1;32m   2679\u001b[0m     cv \u001b[38;5;241m=\u001b[39m CVClass(test_size\u001b[38;5;241m=\u001b[39mn_test, train_size\u001b[38;5;241m=\u001b[39mn_train, random_state\u001b[38;5;241m=\u001b[39mrandom_state)\n\u001b[1;32m   2681\u001b[0m     train, test \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m(cv\u001b[38;5;241m.\u001b[39msplit(X\u001b[38;5;241m=\u001b[39marrays[\u001b[38;5;241m0\u001b[39m], y\u001b[38;5;241m=\u001b[39mstratify))\n\u001b[0;32m-> 2683\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2684\u001b[0m \u001b[43m    \u001b[49m\u001b[43mchain\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_iterable\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2685\u001b[0m \u001b[43m        \u001b[49m\u001b[43m(\u001b[49m\u001b[43m_safe_indexing\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_safe_indexing\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43ma\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43marrays\u001b[49m\n\u001b[1;32m   2686\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2687\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/sklearn/model_selection/_split.py:2685\u001b[0m, in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m   2679\u001b[0m     cv \u001b[38;5;241m=\u001b[39m CVClass(test_size\u001b[38;5;241m=\u001b[39mn_test, train_size\u001b[38;5;241m=\u001b[39mn_train, random_state\u001b[38;5;241m=\u001b[39mrandom_state)\n\u001b[1;32m   2681\u001b[0m     train, test \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m(cv\u001b[38;5;241m.\u001b[39msplit(X\u001b[38;5;241m=\u001b[39marrays[\u001b[38;5;241m0\u001b[39m], y\u001b[38;5;241m=\u001b[39mstratify))\n\u001b[1;32m   2683\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(\n\u001b[1;32m   2684\u001b[0m     chain\u001b[38;5;241m.\u001b[39mfrom_iterable(\n\u001b[0;32m-> 2685\u001b[0m         (\u001b[43m_safe_indexing\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m)\u001b[49m, _safe_indexing(a, test)) \u001b[38;5;28;01mfor\u001b[39;00m a \u001b[38;5;129;01min\u001b[39;00m arrays\n\u001b[1;32m   2686\u001b[0m     )\n\u001b[1;32m   2687\u001b[0m )\n",
      "File \u001b[0;32m~/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/sklearn/utils/__init__.py:388\u001b[0m, in \u001b[0;36m_safe_indexing\u001b[0;34m(X, indices, axis)\u001b[0m\n\u001b[1;32m    386\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _array_indexing(X, indices, indices_dtype, axis\u001b[38;5;241m=\u001b[39maxis)\n\u001b[1;32m    387\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 388\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_list_indexing\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindices\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindices_dtype\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/sklearn/utils/__init__.py:223\u001b[0m, in \u001b[0;36m_list_indexing\u001b[0;34m(X, key, key_dtype)\u001b[0m\n\u001b[1;32m    221\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(compress(X, key))\n\u001b[1;32m    222\u001b[0m \u001b[38;5;66;03m# key is a integer array-like of key\u001b[39;00m\n\u001b[0;32m--> 223\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m [X[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m key]\n",
      "File \u001b[0;32m~/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/sklearn/utils/__init__.py:223\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    221\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(compress(X, key))\n\u001b[1;32m    222\u001b[0m \u001b[38;5;66;03m# key is a integer array-like of key\u001b[39;00m\n\u001b[0;32m--> 223\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m [\u001b[43mX\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m key]\n",
      "Cell \u001b[0;32mIn[1], line 27\u001b[0m, in \u001b[0;36mCustomDataset.__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCUDA device name:\u001b[39m\u001b[38;5;124m\"\u001b[39m, torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mget_device_name(\u001b[38;5;241m0\u001b[39m))  \u001b[38;5;66;03m# Assuming you have one GPU, get its name\u001b[39;00m\n\u001b[1;32m     26\u001b[0m \u001b[38;5;66;03m# Move tensors to GPU\u001b[39;00m\n\u001b[0;32m---> 27\u001b[0m features \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfeatures\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     28\u001b[0m target \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtargets[idx]\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     29\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTensor device:\u001b[39m\u001b[38;5;124m\"\u001b[39m, features\u001b[38;5;241m.\u001b[39mdevice)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'to'"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import Dataset\n",
    "import torch.nn as nn  \n",
    "import torch.optim as optim\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, csv_file):\n",
    "        self.data = pd.read_csv(csv_file)\n",
    "        self.features = self.data.iloc[:, :-1].values\n",
    "        self.targets = self.data.iloc[:, -1].values\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        features = torch.tensor(self.features[idx], dtype=torch.float32)\n",
    "        target = torch.tensor(self.targets[idx], dtype=torch.float32)\n",
    "        if torch.cuda.is_available():\n",
    "            # CUDA is available, print CUDA device information\n",
    "            print(\"CUDA is available! Using GPU.\")\n",
    "            print(\"Number of CUDA devices:\", torch.cuda.device_count())\n",
    "            print(\"CUDA device name:\", torch.cuda.get_device_name(0))  # Assuming you have one GPU, get its name\n",
    "            # Move tensors to GPU\n",
    "            features = self.features[idx].to('cuda')\n",
    "            target = self.targets[idx].to('cuda')\n",
    "            print(\"Tensor device:\", features.device)\n",
    "        return features, target\n",
    "\n",
    "csv_file = \"./MEFAR_MID.csv\"\n",
    "dataset = CustomDataset(csv_file)\n",
    "\n",
    "train_set, test_set = train_test_split(dataset, test_size=0.2, random_state=42)\n",
    "\n",
    "train_loader = DataLoader(train_set, batch_size=10, shuffle=True)\n",
    "test_loader = DataLoader(test_set, batch_size=1, shuffle=False)\n",
    "\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.in_dim = 17\n",
    "        self.out_dim = 1\n",
    "        self.fc1 = nn.Linear(self.in_dim, 16)\n",
    "        self.fc2 = nn.Linear(16, 8)\n",
    "        self.fc3 = nn.Linear(8, 4)\n",
    "        self.fc4 = nn.Linear(4, 2)\n",
    "        self.fc5 = nn.Linear(2, self.out_dim)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.log_softmax = nn.LogSoftmax(dim=1)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        a1 = self.relu(self.fc1(x))\n",
    "        a2 = self.relu(self.fc2(a1))\n",
    "        a3 = self.relu(self.fc3(a2))\n",
    "        a4 = self.relu(self.fc4(a3))\n",
    "        output = self.fc5(a4)  # Pas besoin de log_softmax pour la régression\n",
    "        return output\n",
    "\n",
    "model = MLP()\n",
    "criterion = nn.MSELoss()  # Utilisation de MSELoss pour la régression\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.1)\n",
    "\n",
    "for epoch in range(2):\n",
    "    running_loss = 0.0\n",
    "    ancienRunning=-1\n",
    "    for i, data in enumerate(train_loader, 0):\n",
    "        if (abs(ancienRunning-running_loss)<0.001):\n",
    "            optimizer = optim.SGD(model.parameters(), lr=0.000001)\n",
    "            \n",
    "        ancienRunning=running_loss\n",
    "        inputs, labels = data\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs.squeeze(), labels)  # Squeeze pour éliminer les dimensions inutiles\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "        \n",
    "        \n",
    "        if (i + 1) % 2000 == 0:\n",
    "            print('[%d, %5d] loss: %.3f' % (epoch + 1, i + 1, running_loss / 2000))\n",
    "            running_loss = 0.0\n",
    "\n",
    "print('Finished Training')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "43b89f23-8a68-4efe-9056-73142daaea6f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,  2000] loss: 0.253\n",
      "[1,  4000] loss: 0.253\n",
      "[1,  6000] loss: 0.253\n",
      "[1,  8000] loss: 0.253\n",
      "[1, 10000] loss: 0.253\n",
      "[1, 12000] loss: 0.253\n",
      "[1, 14000] loss: 0.253\n",
      "[1, 16000] loss: 0.253\n",
      "[1, 18000] loss: 0.252\n",
      "[1, 20000] loss: 0.253\n",
      "[1, 22000] loss: 0.253\n",
      "[1, 24000] loss: 0.252\n",
      "[1, 26000] loss: 0.253\n",
      "[1, 28000] loss: 0.253\n",
      "[1, 30000] loss: 0.252\n",
      "[1, 32000] loss: 0.253\n",
      "[1, 34000] loss: 0.253\n",
      "[1, 36000] loss: 0.253\n",
      "[1, 38000] loss: 0.253\n",
      "[1, 40000] loss: 0.253\n",
      "[1, 42000] loss: 0.253\n",
      "[1, 44000] loss: 0.252\n",
      "[1, 46000] loss: 0.253\n",
      "[1, 48000] loss: 0.253\n",
      "[1, 50000] loss: 0.253\n",
      "[1, 52000] loss: 0.253\n",
      "[1, 54000] loss: 0.253\n",
      "[1, 56000] loss: 0.253\n",
      "[1, 58000] loss: 0.253\n",
      "[1, 60000] loss: 0.253\n",
      "[1, 62000] loss: 0.253\n",
      "[1, 64000] loss: 0.253\n",
      "[1, 66000] loss: 0.253\n",
      "[1, 68000] loss: 0.252\n",
      "[1, 70000] loss: 0.253\n",
      "[1, 72000] loss: 0.253\n",
      "[2,  2000] loss: 0.253\n",
      "[2,  4000] loss: 0.253\n",
      "[2,  6000] loss: 0.253\n",
      "[2,  8000] loss: 0.253\n",
      "[2, 10000] loss: 0.253\n",
      "[2, 12000] loss: 0.253\n",
      "[2, 14000] loss: 0.252\n",
      "[2, 16000] loss: 0.253\n",
      "[2, 18000] loss: 0.253\n",
      "[2, 20000] loss: 0.253\n",
      "[2, 22000] loss: 0.253\n",
      "[2, 24000] loss: 0.253\n",
      "[2, 26000] loss: 0.253\n",
      "[2, 28000] loss: 0.253\n",
      "[2, 30000] loss: 0.253\n",
      "[2, 32000] loss: 0.253\n",
      "[2, 34000] loss: 0.253\n",
      "[2, 36000] loss: 0.253\n",
      "[2, 38000] loss: 0.253\n",
      "[2, 40000] loss: 0.253\n",
      "[2, 42000] loss: 0.253\n",
      "[2, 44000] loss: 0.253\n",
      "[2, 46000] loss: 0.253\n",
      "[2, 48000] loss: 0.253\n",
      "[2, 50000] loss: 0.253\n",
      "[2, 52000] loss: 0.253\n",
      "[2, 54000] loss: 0.253\n",
      "[2, 56000] loss: 0.252\n",
      "[2, 58000] loss: 0.253\n",
      "[2, 60000] loss: 0.253\n",
      "[2, 62000] loss: 0.253\n",
      "[2, 64000] loss: 0.253\n",
      "[2, 66000] loss: 0.253\n",
      "[2, 68000] loss: 0.253\n",
      "[2, 70000] loss: 0.253\n",
      "[2, 72000] loss: 0.253\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02fc58ad-66ed-45b4-b9e7-530e30418aeb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_p310",
   "language": "python",
   "name": "conda_pytorch_p310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
