{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "949d0792-ae36-494a-ae76-1678cc34945f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import Dataset\n",
    "import torch.nn as nn  \n",
    "import torch.optim as optim\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b43ab93d-e6b0-4636-afd9-25c111e8e3f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, csv_file):\n",
    "        self.data = pd.read_csv(csv_file)\n",
    "        self.features = self.data.iloc[:, :-1].values\n",
    "        self.targets = self.data.iloc[:, -1].values\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        features = torch.tensor(self.features[idx], dtype=torch.float32)\n",
    "        target = torch.tensor(self.targets[idx], dtype=torch.float32)  \n",
    "        return features, target\n",
    "\n",
    "csv_file = \"./MEFAR_MID.csv\"\n",
    "dataset = CustomDataset(csv_file)\n",
    "\n",
    "train_set, test_set = train_test_split(dataset, test_size=0.2, random_state=42)\n",
    "\n",
    "train_loader = DataLoader(train_set, batch_size=8, shuffle=True)\n",
    "test_loader = DataLoader(test_set, batch_size=1, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9f31c657-4182-42bb-88b0-7b10320229e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.in_dim = 17\n",
    "        self.out_dim = 1\n",
    "        self.fc1 = nn.Linear(self.in_dim, 16)\n",
    "        self.fc2 = nn.Linear(16, 8)\n",
    "        self.fc3 = nn.Linear(8, 4)\n",
    "        self.fc4 = nn.Linear(4, 2)\n",
    "        self.fc5 = nn.Linear(2, self.out_dim)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.log_softmax = nn.LogSoftmax(dim=1)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        a1 = self.relu(self.fc1(x))\n",
    "        a2 = self.relu(self.fc2(a1))\n",
    "        a3 = self.relu(self.fc3(a2))\n",
    "        a4 = self.relu(self.fc4(a3))\n",
    "        output = self.fc5(a4)  # Pas besoin de log_softmax pour la régression\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dbebed3a-5bb3-44f4-b610-9c4ba8338228",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,  2000] loss: 0.250\n",
      "[1,  4000] loss: 0.223\n",
      "[1,  6000] loss: 0.220\n",
      "[1,  8000] loss: 0.216\n",
      "[1, 10000] loss: 0.211\n",
      "[1, 12000] loss: 0.202\n",
      "[1, 14000] loss: 0.190\n",
      "[1, 16000] loss: 0.174\n",
      "[1, 18000] loss: 0.162\n",
      "[1, 20000] loss: 0.156\n",
      "[1, 22000] loss: 0.150\n",
      "[1, 24000] loss: 0.142\n",
      "[1, 26000] loss: 0.139\n",
      "[1, 28000] loss: 0.137\n",
      "[1, 30000] loss: 0.130\n",
      "[1, 32000] loss: 0.128\n",
      "[1, 34000] loss: 0.127\n",
      "[1, 36000] loss: 0.126\n",
      "[1, 38000] loss: 0.120\n",
      "[1, 40000] loss: 0.125\n",
      "[1, 42000] loss: 0.120\n",
      "[1, 44000] loss: 0.118\n",
      "[1, 46000] loss: 0.117\n",
      "[1, 48000] loss: 0.114\n",
      "[1, 50000] loss: 0.111\n",
      "[1, 52000] loss: 0.110\n",
      "[1, 54000] loss: 0.108\n",
      "[1, 56000] loss: 0.107\n",
      "[1, 58000] loss: 0.106\n",
      "[1, 60000] loss: 0.107\n",
      "[1, 62000] loss: 0.102\n",
      "[1, 64000] loss: 0.103\n",
      "[1, 66000] loss: 0.102\n",
      "[1, 68000] loss: 0.100\n",
      "[1, 70000] loss: 0.101\n",
      "[1, 72000] loss: 0.098\n",
      "[1, 74000] loss: 0.098\n",
      "[1, 76000] loss: 0.100\n",
      "[1, 78000] loss: 0.096\n",
      "[1, 80000] loss: 0.096\n",
      "[1, 82000] loss: 0.095\n",
      "[1, 84000] loss: 0.098\n",
      "[1, 86000] loss: 0.098\n",
      "[1, 88000] loss: 0.097\n",
      "[1, 90000] loss: 0.091\n",
      "[1, 92000] loss: 0.096\n",
      "[2,  2000] loss: 0.096\n",
      "[2,  4000] loss: 0.092\n",
      "[2,  6000] loss: 0.092\n",
      "[2,  8000] loss: 0.091\n",
      "[2, 10000] loss: 0.090\n",
      "[2, 12000] loss: 0.090\n",
      "[2, 14000] loss: 0.091\n",
      "[2, 16000] loss: 0.088\n",
      "[2, 18000] loss: 0.090\n",
      "[2, 20000] loss: 0.087\n",
      "[2, 22000] loss: 0.089\n",
      "[2, 24000] loss: 0.088\n",
      "[2, 26000] loss: 0.089\n",
      "[2, 28000] loss: 0.087\n",
      "[2, 30000] loss: 0.088\n",
      "[2, 32000] loss: 0.089\n",
      "[2, 34000] loss: 0.086\n",
      "[2, 36000] loss: 0.086\n",
      "[2, 38000] loss: 0.084\n",
      "[2, 40000] loss: 0.087\n",
      "[2, 42000] loss: 0.086\n",
      "[2, 44000] loss: 0.086\n",
      "[2, 46000] loss: 0.085\n",
      "[2, 48000] loss: 0.086\n",
      "[2, 50000] loss: 0.085\n",
      "[2, 52000] loss: 0.086\n",
      "[2, 54000] loss: 0.089\n",
      "[2, 56000] loss: 0.083\n",
      "[2, 58000] loss: 0.082\n",
      "[2, 60000] loss: 0.079\n",
      "[2, 62000] loss: 0.083\n",
      "[2, 64000] loss: 0.083\n",
      "[2, 66000] loss: 0.081\n",
      "[2, 68000] loss: 0.084\n",
      "[2, 70000] loss: 0.086\n",
      "[2, 72000] loss: 0.083\n",
      "[2, 74000] loss: 0.079\n",
      "[2, 76000] loss: 0.082\n",
      "[2, 78000] loss: 0.078\n",
      "[2, 80000] loss: 0.080\n",
      "[2, 82000] loss: 0.081\n",
      "[2, 84000] loss: 0.082\n",
      "[2, 86000] loss: 0.079\n",
      "[2, 88000] loss: 0.080\n",
      "[2, 90000] loss: 0.081\n",
      "[2, 92000] loss: 0.079\n",
      "[3,  2000] loss: 0.079\n",
      "[3,  4000] loss: 0.077\n",
      "[3,  6000] loss: 0.078\n",
      "[3,  8000] loss: 0.074\n",
      "[3, 10000] loss: 0.078\n",
      "[3, 12000] loss: 0.076\n",
      "[3, 14000] loss: 0.081\n",
      "[3, 16000] loss: 0.075\n",
      "[3, 18000] loss: 0.078\n",
      "[3, 20000] loss: 0.075\n",
      "[3, 22000] loss: 0.080\n",
      "[3, 24000] loss: 0.075\n",
      "[3, 26000] loss: 0.077\n",
      "[3, 28000] loss: 0.073\n",
      "[3, 30000] loss: 0.078\n",
      "[3, 32000] loss: 0.077\n",
      "[3, 34000] loss: 0.073\n",
      "[3, 36000] loss: 0.074\n",
      "[3, 38000] loss: 0.075\n",
      "[3, 40000] loss: 0.073\n",
      "[3, 42000] loss: 0.078\n",
      "[3, 44000] loss: 0.080\n",
      "[3, 46000] loss: 0.073\n",
      "[3, 48000] loss: 0.074\n",
      "[3, 50000] loss: 0.080\n",
      "[3, 52000] loss: 0.077\n",
      "[3, 54000] loss: 0.072\n",
      "[3, 56000] loss: 0.075\n",
      "[3, 58000] loss: 0.072\n",
      "[3, 60000] loss: 0.074\n",
      "[3, 62000] loss: 0.076\n",
      "[3, 64000] loss: 0.076\n",
      "[3, 66000] loss: 0.072\n",
      "[3, 68000] loss: 0.072\n",
      "[3, 70000] loss: 0.077\n",
      "[3, 72000] loss: 0.072\n",
      "[3, 74000] loss: 0.072\n",
      "[3, 76000] loss: 0.075\n",
      "[3, 78000] loss: 0.071\n",
      "[3, 80000] loss: 0.072\n",
      "[3, 82000] loss: 0.071\n",
      "[3, 84000] loss: 0.073\n",
      "[3, 86000] loss: 0.074\n",
      "[3, 88000] loss: 0.072\n",
      "[3, 90000] loss: 0.071\n",
      "[3, 92000] loss: 0.071\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "model = MLP()\n",
    "criterion = nn.MSELoss()  # Utilisation de MSELoss pour la régression\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.1)\n",
    "\n",
    "for epoch in range(3):\n",
    "    running_loss = 0.0\n",
    "    ancienRunning=-1\n",
    "    for i, data in enumerate(train_loader, 0):\n",
    "        if (abs(ancienRunning-running_loss)<0.001):\n",
    "            optimizer = optim.SGD(model.parameters(), lr=0.00001)\n",
    "        inputs, labels = data\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs.squeeze(), labels)  # Squeeze pour éliminer les dimensions inutiles\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "        \n",
    "        \n",
    "        if (i + 1) % 2000 == 0:\n",
    "            print('[%d, %5d] loss: %.3f' % (epoch + 1, i + 1, running_loss / 2000))\n",
    "            running_loss = 0.0\n",
    "\n",
    "print('Finished Training')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "08d426cb-cf1a-4db3-8928-9ef2adc7cd98",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.0676, Accuracy: 91.69%\n"
     ]
    }
   ],
   "source": [
    "def test_model(model, test_loader, criterion):\n",
    "    model.eval()  # Mettre le modèle en mode évaluation\n",
    "    test_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():  # Désactiver le calcul des gradients pendant l'évaluation\n",
    "        for inputs, labels in test_loader:\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs.squeeze(), labels.float())  # Convertir les étiquettes en type float\n",
    "            test_loss += loss.item()\n",
    "            # Calcul de la précision\n",
    "            predicted = torch.round(outputs).squeeze()  # Arrondir les prédictions\n",
    "            #print(outputs ,\"     rechercher : \" , labels) \n",
    "            \n",
    "            correct += (predicted == labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "    \n",
    "    # Afficher les résultats\n",
    "    avg_loss = test_loss / len(test_loader)\n",
    "    accuracy = correct / total\n",
    "    print('Test Loss: {:.4f}, Accuracy: {:.2f}%'.format(avg_loss, accuracy * 100))\n",
    "\n",
    "# Utiliser la fonction test_model pour évaluer le modèle\n",
    "test_model(model, test_loader, criterion)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e90f1770-386c-4eba-a425-cd0e10d9e925",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'FligneBS8.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "11df5597-a5c4-456c-92f8-b1fe5ce18aed",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fc1.weight tensor([[-1.9746e-01,  2.0859e-01, -1.4665e-01,  2.0182e-01, -1.0873e-01,\n",
      "          1.8891e-01,  2.6728e-01,  1.1657e-01,  9.7010e-02, -2.7057e-01,\n",
      "         -1.7029e-01,  2.0670e-01, -1.3028e-01, -1.5310e-01, -5.5562e-03,\n",
      "         -1.9537e-01,  2.5240e-01],\n",
      "        [ 5.7299e-02,  3.4555e+00,  5.8151e+00, -3.8225e-01, -1.1544e-01,\n",
      "         -9.1647e-01,  1.4636e+00, -1.7750e-01,  3.8450e-01, -2.2796e-01,\n",
      "          1.1218e-01, -1.4025e-03, -1.9629e-01,  1.3009e-02, -2.2849e-01,\n",
      "          2.6186e-02,  1.1221e-01],\n",
      "        [ 1.0695e-01,  4.4050e+00, -3.6300e+00, -1.0728e+00, -1.6041e+00,\n",
      "          7.8320e-01, -2.2155e+00, -2.2805e-01,  1.0144e-01, -4.8141e-02,\n",
      "         -2.2623e-01,  4.4300e-02, -4.2959e-01, -1.7079e-01, -9.5780e-03,\n",
      "         -9.6853e-02,  8.3455e-03],\n",
      "        [-6.0935e-02, -3.6493e+00, -7.3118e-01,  7.6729e-01,  3.8429e+00,\n",
      "         -1.1601e+00,  7.2359e+00,  2.0755e-01, -4.4275e-01, -6.2448e-02,\n",
      "          1.0025e-01, -3.6796e-02,  1.8643e-01, -1.3468e-01, -9.9804e-02,\n",
      "         -1.4080e-01,  7.1249e-02],\n",
      "        [-3.9204e-02, -4.4729e+00,  1.5664e-01, -1.4612e+00,  7.0312e+00,\n",
      "         -5.5182e-02, -4.3167e+00,  1.0477e-01, -1.0348e-01,  3.5686e-02,\n",
      "          6.9448e-02,  3.6525e-02, -3.2023e-02, -2.4784e-01,  3.3490e-01,\n",
      "          1.3237e-01,  1.3338e-01],\n",
      "        [ 2.3066e-01,  6.9036e-02, -6.4145e-01, -5.1860e-01, -2.9719e+00,\n",
      "          5.6623e+00,  2.5302e+00,  8.2482e-02, -3.5583e-01,  2.1156e-01,\n",
      "         -1.2097e-01,  9.1544e-02, -1.9868e-01, -1.0775e-01, -2.0581e-02,\n",
      "         -4.9193e-03,  8.5071e-02],\n",
      "        [ 2.3659e-01, -3.0132e+00, -4.3786e+00,  3.5316e-01, -2.3157e+00,\n",
      "         -4.4857e-01,  2.9250e+00, -2.2474e-01, -2.9502e-02, -1.2844e-01,\n",
      "          1.1093e-01,  1.3284e-01, -3.0911e-01, -1.3514e-01,  2.1485e-01,\n",
      "         -6.6675e-02,  1.1055e-02],\n",
      "        [ 2.6742e-01,  3.2859e+00, -1.1939e+00,  1.3377e+00,  3.0916e+00,\n",
      "         -7.0124e-01,  8.3994e+00,  4.2136e-01, -2.2865e-01,  1.5587e-01,\n",
      "         -1.0251e-01,  1.1021e-01, -5.2066e-01,  1.7493e-01,  1.1757e-01,\n",
      "         -2.6513e-02,  5.8997e-04],\n",
      "        [ 2.4679e-02,  4.2648e+00, -3.9610e+00, -5.3900e-01,  2.5573e+00,\n",
      "          2.1519e+00, -8.1244e-01, -4.3362e-02, -1.3917e-01,  6.3527e-02,\n",
      "         -2.4791e-02,  1.7225e-01,  1.1675e-01,  5.2466e-02,  2.8108e-01,\n",
      "         -7.1636e-02,  1.0819e-01],\n",
      "        [-7.4512e-03, -2.5377e+00, -6.2304e+00,  1.0553e+00,  7.0371e-01,\n",
      "          2.4550e+00,  9.9223e-01,  1.9967e-02, -4.4346e-02,  4.9121e-02,\n",
      "         -1.1063e-01,  1.0570e-01, -3.0665e-01, -6.1331e-02,  1.9941e-02,\n",
      "         -1.0036e-01, -1.2007e-01],\n",
      "        [ 8.3866e-02, -8.1281e-01,  1.9565e+00,  1.1494e-01,  1.2785e+00,\n",
      "         -1.2139e+00, -1.2229e+00, -5.4910e-02, -8.0111e-02,  1.1458e-01,\n",
      "         -3.6474e-01,  3.7815e-01, -5.8282e-04,  5.8965e-01, -1.5252e-02,\n",
      "          5.7393e-02,  3.5098e-02],\n",
      "        [ 8.6920e-02, -4.7753e-01,  5.0040e-01,  1.0688e+00, -2.3690e+00,\n",
      "         -1.0725e+00,  2.4330e-02, -8.3529e-02,  1.8116e-01, -1.8540e-01,\n",
      "          1.3496e-01,  2.2067e-01, -7.4655e-02, -3.4872e-01, -1.4421e-01,\n",
      "         -6.7778e-02, -2.4935e-02],\n",
      "        [ 2.0967e-01, -7.0707e+00,  7.9852e+00, -3.1430e-01, -1.5313e-01,\n",
      "          1.0725e+00, -2.2665e+00, -1.3749e-02, -8.3263e-02,  2.5750e-02,\n",
      "         -2.3206e-01,  2.3971e-01, -1.0138e-01,  4.6983e-01,  1.1796e-01,\n",
      "          4.8418e-02, -3.8078e-02],\n",
      "        [-1.5642e-01,  6.6843e-01, -2.2895e+00,  1.9723e+00, -6.6313e-01,\n",
      "          1.1035e+00,  4.0252e+00,  2.0019e-01, -4.0746e-02, -1.8858e-01,\n",
      "          3.3074e-01,  2.2711e-01, -7.9190e-02,  1.7791e-01,  9.1706e-02,\n",
      "         -4.5215e-02,  3.3038e-03],\n",
      "        [-1.8610e-01, -3.2403e+00, -6.3181e+00,  1.1481e+00,  1.7979e+00,\n",
      "         -1.8969e+00,  9.6203e-01, -2.9444e-02, -4.3167e-01, -1.1626e-01,\n",
      "          1.4354e-02, -6.5820e-03, -8.3177e-02,  2.6526e-02, -3.0647e-01,\n",
      "          4.7819e-02, -4.6235e-02],\n",
      "        [-4.8734e-02,  7.7228e-01,  5.5847e+00,  1.6653e+00, -4.5278e-01,\n",
      "         -2.2634e-01, -7.3401e+00, -6.7254e-02,  3.0095e-01,  1.9425e-02,\n",
      "          1.4849e-01, -2.8023e-01, -1.1457e-01, -1.4778e-01,  2.6360e-01,\n",
      "         -4.3656e-02, -7.2560e-02]])\n",
      "fc2.weight tensor([[-0.0767, -1.7106, -1.9020,  1.1300,  3.0652, -1.2023,  0.2748,  0.9526,\n",
      "         -2.7627, -0.6242, -0.2176,  0.4539, -1.5063,  0.6680, -2.2368,  2.1795],\n",
      "        [ 0.1748, -0.5761, -2.4409,  0.2148,  0.6288,  1.0908, -0.6209, -1.2001,\n",
      "         -0.3046,  0.3275,  0.8788, -0.5675, -1.5272,  1.8411, -1.7573, -1.6898],\n",
      "        [-0.1141, -0.0994, -0.8849, -1.1700, -1.8561, -0.7822, -0.5130,  2.6982,\n",
      "          0.9260, -0.3118,  0.4317,  0.2015,  0.3036, -1.3830, -1.2609, -2.1916],\n",
      "        [-0.1658,  1.3805, -0.7575, -4.0656,  1.2708,  0.6083, -1.9963,  3.2402,\n",
      "          1.0328, -3.6807,  0.1607,  0.6211,  0.4659, -1.5953,  1.3648,  1.0093],\n",
      "        [-0.0934, -2.3815, -2.5118, -0.7451,  1.5665,  1.6232,  2.8518, -2.1094,\n",
      "         -1.7839,  3.1558,  1.5355, -0.1524, -5.0237, -0.8989,  0.2414,  1.6970],\n",
      "        [ 0.3213,  0.5040, -0.6427,  1.3334, -1.1906,  1.4081,  0.4940,  2.4536,\n",
      "         -1.1107, -0.1936, -0.2581,  0.0570,  0.8454, -1.2706, -3.3119, -0.1730],\n",
      "        [ 0.1733,  0.8008, -0.2422, -1.5273, -0.6838,  1.5657,  0.1711, -2.1026,\n",
      "          0.0132, -0.1385, -1.2533, -1.8929, -2.3972,  1.8243, -3.2978, -0.0597],\n",
      "        [ 0.1005,  0.4334,  0.9948, -0.1856, -0.5313,  0.6176, -0.5477, -0.3942,\n",
      "          0.2349, -0.0886, -0.8470,  0.4808, -0.2371,  0.9637, -0.3131, -0.7286]])\n",
      "fc3.weight tensor([[-0.7939, -1.3870, -0.4238,  0.8668, -0.4153, -1.7980, -0.8152,  1.2622],\n",
      "        [-0.0060,  1.4304,  0.1670, -1.3878, -1.3340, -2.8343,  0.3394,  0.0205],\n",
      "        [-2.5342,  1.6057, -1.6971,  1.7182, -1.8691, -0.4035, -2.1582,  1.3437],\n",
      "        [-1.4055,  0.3478, -1.0298,  1.2168, -1.4674, -0.9386,  0.0836,  0.6039]])\n",
      "fc4.weight tensor([[ 0.1548, -0.0956,  0.1310, -0.3257],\n",
      "        [-0.6969, -0.3890, -0.4974,  0.5432]])\n",
      "fc5.weight tensor([[ 0.1138, -0.5833]])\n"
     ]
    }
   ],
   "source": [
    "# Supposons que 'model' soit votre modèle PyTorch\n",
    "# Vous pouvez afficher les poids des neurones comme ceci :\n",
    "for name, param in model.named_parameters():\n",
    "    if 'weight' in name:\n",
    "        print(name, param.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f2a3193-8927-4de6-ae9b-c796610303f9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_p310",
   "language": "python",
   "name": "conda_pytorch_p310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
