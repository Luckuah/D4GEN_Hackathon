{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b083f929-00bd-485d-bff4-ed0f867e7c8e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import traceback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "14cec826-4a69-4d38-a1f9-927d894acdf0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def dataloaderV2(dossier, etat):\n",
    "    # on part d'un dossier racine où chacun des dossiers contenant les données est\n",
    "    # initialise data = tableau final\n",
    "    data = []\n",
    "    # initialise le di;ctionnaire qui va stocker toutes les valeurs de session et class par individu\n",
    "    \n",
    "    #on va parcourir tous les dossier du premier dossier\n",
    "    for dos in os.listdir(dossier):\n",
    "        #on met à jour le path pour pouvoir parcourir le sous dossier\n",
    "        dos_path = os.path.join(dossier, dos)\n",
    "        \n",
    "        sorted_files = sorted(os.listdir(dos_path))\n",
    "        \n",
    "        #on vérifie que c'est bien un dossier\n",
    "        if os.path.isdir(dos_path):\n",
    "            # on va parcourir les fichiers contenant les datas\n",
    "            n_va = 0\n",
    "            for fichier in sorted_files:\n",
    "                #on initialise l'indice de VA qui va vous permettre de parcourir le data final par colonnes\n",
    "                #vérifie que c'est bien un fichier csv\n",
    "                if fichier.endswith(\".csv\") and fichier.split(\"_\")[0].lower()== etat:\n",
    "                    print(\"fichier\", fichier) #okay va dans tous les fichiers\n",
    "                    #met à jour le path pour pouvoir ouvrir le fichier\n",
    "                    filepath = os.path.join(dos_path, fichier)\n",
    "                    try:\n",
    "                        df = pd.read_csv(filepath, header = 0, low_memory=False)\n",
    "                    except Exception as e:\n",
    "                        print(f\"Error reading file '{va}': {e}\")\n",
    "                        \n",
    "                    for indiv in range(len(data)):\n",
    "                        # Expand this individual's list if it doesn't have enough slots\n",
    "                        while len(data[indiv]) <= n_va:\n",
    "                            required_length = n_va + 1\n",
    "                            current_length = len(data[indiv])\n",
    "                            additional_slots_needed = required_length - current_length\n",
    "                            if additional_slots_needed > 0:\n",
    "                                data[indiv].extend([None] * additional_slots_needed)\n",
    "                            \n",
    "                    # on va otérer sur toutes les datas de ce fichier, \n",
    "                    # avec num indiv indice de 0 ua bout, index = index de lignes et row la data\n",
    "                    for indiv, (index, row) in enumerate(df.iterrows()):\n",
    "                        try:\n",
    "                            #print(f\"before indiv: {indiv}, n_va: {n_va}, len(data[indiv]): {len(data[indiv])}\")\n",
    "                            # Ensure the sublist exists and is of the correct length\n",
    "                            while len(data) <= indiv:\n",
    "                                #print(\"data avant ajustement pas d'indiv : \", data) okay les datas sont correctes\n",
    "                                # Extend data list with empty lists as needed\n",
    "                                #data.extend([[] for _ in range(indiv - len(data) + 1)])\n",
    "                                data.extend([[]] * (indiv - len(data) + 1))\n",
    "                                # Diagnostic prints to understand the structure just before the error occurs\n",
    "                                #print(f\"Attempting assignment to data[{indiv}][{n_va}].\")\n",
    "                                #print(f\"len(data): {len(data)}, len(data[{indiv}]): {len(data[indiv])}.\")\n",
    "\n",
    "                                #print(\"data avant ajustement pas d'indiv : \", data)okay les datas sont correctes\n",
    "                            while len(data[indiv]) <= n_va:\n",
    "                                #print(\"rien dans les indiv = pas de va AVANT : \", data) okay les datas sont correctes\n",
    "                                # Extend the sublist with None values as placeholders\n",
    "                                #data[indiv].extend([None for _ in range(n_va - len(data[indiv]) + 1)])\n",
    "                                data[indiv].append([])    \n",
    "                                #data[indiv].append(None)\n",
    "                            #print(f\"after indiv: {indiv}, n_va: {n_va}, len(data[indiv]): {len(data[indiv])}\")\n",
    "                            \n",
    "                                #print(\"rien dans les indiv = pas de va APRES : \", data)\n",
    "                            # Now safe to assign the value\n",
    "                            #print(f\"Right before assignment to data[{indiv}][{n_va}]: len(data): {len(data)}, len(data[{indiv}]): {len(data[indiv])}, len(data[{indiv}][{n_va}]): 'Will be set'\")\n",
    "\n",
    "                           \n",
    "                            # Extract session and class if already present\n",
    "                            if len(data[indiv]) >= 2:\n",
    "                                #print(\"session class deja la AVANT : \", data[indiv])# okay les datas sont correctes\n",
    "                                session_data, class_data = data[indiv][-2:]  # Extract existing session and class\n",
    "                                data[indiv] = data[indiv][:-2]  # Remove session and class from the current list\n",
    "                                #print(\"session class deja la APRES : \", data) okay les datas sont correctes\n",
    "                                #print(\"session class deja la APRES : \", data[indiv]) okay les datas sont correctes\n",
    "                                #print(\"session : \", session_data, \" class : \", class_data) okay les datas sont correctes\n",
    "                            else:\n",
    "                                #print(\"recup session class depuis datas\")\n",
    "                                session_data, class_data = row.iloc[-2], row.iloc[-1]  # Get new session and class\n",
    "                                #print(\"session : \", session_data, \" class : \", class_data) print(\"session : \", session_data, \" class : \", class_data\n",
    "\n",
    "                            # For each individual, append the new row data, excluding session and class\n",
    "                            #row_data = row.iloc[:-2].tolist()\n",
    "                            #data[indiv].extend(row_data)  # Append the new row data\n",
    "                            \n",
    "                           # print(\"data avant append nouvelle va : \", data[indiv][n_va]) okay les datas sont correctes\n",
    "                            data[indiv].append(row.iloc[:-2].tolist())\n",
    "                            #print(\"data apres append nouvelle va : \", data[indiv][n_va]) okay les datas sont correctes\n",
    "                            # Re-append the session and class data at the end\n",
    "                            #print(\"data avant append nouvelle va append session/class: \", data[indiv]) okay les datas sont correctes\n",
    "                            data[indiv].append([session_data])\n",
    "                            #print(\"data apres append nouvelle va append session: \", data[indiv]) okay les datas sont correctes\n",
    "                            data[indiv].append([class_data])\n",
    "                            #print(\"data apres append nouvelle va append class: \", data[indiv]) okay les datas sont correctes\n",
    "                            \n",
    "                        #except (IndexError, TypeError):\n",
    "                        except (IndexError, TypeError) as e:\n",
    "                            print(f\"error: {type(e).name}\")\n",
    "                            #if isinstance(row.iloc[:-2], pd.Series):\n",
    "                             #   data.append([row.iloc[:-2].tolist()])\n",
    "                            #traceback.print_exc()\n",
    "                            # Properly append a new sublist if catching an IndexError before this logic\n",
    "                            #if isinstance(row.iloc[:-2], pd.Series):\n",
    "                            #    data.append([row.iloc[:-2].tolist()])\n",
    "                            #    print(\"error\")\n",
    "                            #else:\n",
    "                                # Handle unexpected data format\n",
    "                             #   data.append([None])\n",
    "                            \n",
    "                    n_va +=1\n",
    "\n",
    "    return data    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "8ce67738-d718-4414-9918-f8b62057310b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#print(\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "18ff64b4-4ca0-4b3f-a790-2cbc85729768",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fichier NORMAL_ACC_x_EVENING.csv\n",
      "fichier NORMAL_ACC_y_EVENING.csv\n",
      "fichier NORMAL_ACC_z_EVENING.csv\n",
      "fichier NORMAL_BVP_EVENING.csv\n",
      "fichier NORMAL_EDA_EVENING.csv\n",
      "fichier NORMAL_EEG_Alpha1_EVENING.csv\n",
      "fichier NORMAL_EEG_Alpha2_EVENING.csv\n",
      "fichier NORMAL_EEG_Attention_EVENING.csv\n",
      "fichier NORMAL_EEG_Beta1_EVENING.csv\n",
      "fichier NORMAL_EEG_Beta2_EVENING.csv\n",
      "fichier NORMAL_ACC_x_MORNING.csv\n",
      "fichier NORMAL_ACC_y_MORNING.csv\n",
      "fichier NORMAL_ACC_z_MORNING.csv\n",
      "fichier NORMAL_BVP_MORNING.csv\n",
      "fichier NORMAL_EDA_MORNING.csv\n",
      "fichier NORMAL_EEG_Alpha1_MORNING.csv\n",
      "fichier NORMAL_EEG_Alpha2_MORNING.csv\n",
      "fichier NORMAL_EEG_Attention_MORNING.csv\n",
      "fichier NORMAL_EEG_Beta1_MORNING.csv\n",
      "fichier NORMAL_EEG_Beta2_MORNING.csv\n",
      "LEN DATA\n",
      "1019\n",
      "LEN DATA[0]\n",
      "23\n",
      "LEN COntainer\n",
      "0\n",
      "3840\n",
      "3840\n",
      "3840\n",
      "7680\n",
      "480\n",
      "120\n",
      "120\n",
      "120\n",
      "120\n",
      "120\n",
      "3840\n",
      "3840\n",
      "3840\n",
      "7680\n",
      "480\n",
      "120\n",
      "120\n",
      "120\n",
      "120\n",
      "120\n",
      "1\n",
      "1\n",
      "fichier FATIGUE_ACC_x_EVENING.csv\n",
      "fichier FATIGUE_ACC_y_EVENING.csv\n",
      "fichier FATIGUE_ACC_z_EVENING.csv\n",
      "fichier FATIGUE_BVP_EVENING.csv\n",
      "fichier FATIGUE_EDA_EVENING.csv\n",
      "fichier FATIGUE_EEG_Alpha1_EVENING.csv\n",
      "fichier FATIGUE_EEG_Alpha2_EVENING.csv\n",
      "fichier FATIGUE_EEG_Attention_EVENING.csv\n",
      "fichier FATIGUE_EEG_Beta1_EVENING.csv\n",
      "fichier FATIGUE_EEG_Beta2_EVENING.csv\n",
      "fichier FATIGUE_ACC_x_MORNING.csv\n",
      "fichier FATIGUE_ACC_y_MORNING.csv\n",
      "fichier FATIGUE_ACC_z_MORNING.csv\n",
      "fichier FATIGUE_BVP_MORNING.csv\n",
      "fichier FATIGUE_EDA_MORNING.csv\n",
      "fichier FATIGUE_EEG_Alpha1_MORNING.csv\n",
      "fichier FATIGUE_EEG_Alpha2_MORNING.csv\n",
      "fichier FATIGUE_EEG_Attention_MORNING.csv\n",
      "fichier FATIGUE_EEG_Beta1_MORNING.csv\n",
      "fichier FATIGUE_EEG_Beta2_MORNING.csv\n",
      "LEN DATA\n",
      "1090\n",
      "LEN DATA[0]\n",
      "23\n",
      "LEN COntainer\n",
      "0\n",
      "3840\n",
      "3840\n",
      "3840\n",
      "7680\n",
      "480\n",
      "120\n",
      "120\n",
      "120\n",
      "120\n",
      "120\n",
      "3840\n",
      "3840\n",
      "3840\n",
      "7680\n",
      "480\n",
      "120\n",
      "120\n",
      "120\n",
      "120\n",
      "120\n",
      "1\n",
      "1\n",
      "[[[[[[[[[[[[[[[[[[[[1]]]]]]]]]]]]]]]]]]]]\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[55], line 23\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28mlen\u001b[39m(data_f[\u001b[38;5;241m0\u001b[39m][i]))\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28mprint\u001b[39m(data_f[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m2\u001b[39m])\n\u001b[0;32m---> 23\u001b[0m data_n \u001b[38;5;241m=\u001b[39m \u001b[43mnettoyage\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_n\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     24\u001b[0m data_f \u001b[38;5;241m=\u001b[39m nettoyage(data_f)\n\u001b[1;32m     30\u001b[0m data \u001b[38;5;241m=\u001b[39m data_f \u001b[38;5;241m+\u001b[39m data_n\n",
      "Cell \u001b[0;32mIn[50], line 13\u001b[0m, in \u001b[0;36mnettoyage\u001b[0;34m(dat)\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(dat)):\n\u001b[1;32m     12\u001b[0m     dat[i]\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m---> 13\u001b[0m     dat[i][\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mflatten\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdat\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     14\u001b[0m     dat[i][\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m2\u001b[39m] \u001b[38;5;241m=\u001b[39m flatten(dat[i][\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m2\u001b[39m])\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m dat\n",
      "Cell \u001b[0;32mIn[50], line 3\u001b[0m, in \u001b[0;36mflatten\u001b[0;34m(arr)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mflatten\u001b[39m(arr):\n\u001b[1;32m      2\u001b[0m     flattened \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m----> 3\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m element \u001b[38;5;129;01min\u001b[39;00m arr:\n\u001b[1;32m      4\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(element, \u001b[38;5;28mlist\u001b[39m):\n\u001b[1;32m      5\u001b[0m             flattened\u001b[38;5;241m.\u001b[39mextend(flatten(element))\n",
      "\u001b[0;31mTypeError\u001b[0m: 'NoneType' object is not iterable"
     ]
    }
   ],
   "source": [
    "directory_path = \"./RAW\"\n",
    "data_n = dataloaderV2(directory_path, \"normal\")\n",
    "\n",
    "print(\"LEN DATA\")\n",
    "print(len(data_n))\n",
    "print(\"LEN DATA[0]\")\n",
    "print(len(data_n[0]))\n",
    "print(\"LEN COntainer\")\n",
    "for i in range(len(data_n[0])):\n",
    "    print(len(data_n[0][i]))\n",
    "\n",
    "data_f = dataloaderV2(directory_path, \"fatigue\")\n",
    "\n",
    "print(\"LEN DATA\")\n",
    "print(len(data_f))\n",
    "print(\"LEN DATA[0]\")\n",
    "print(len(data_f[0]))\n",
    "print(\"LEN COntainer\")\n",
    "for i in range(len(data_f[0])):\n",
    "    print(len(data_f[0][i]))\n",
    "\n",
    "print(data_f[0][-2])\n",
    "data_n = nettoyage(data_n)\n",
    "data_f = nettoyage(data_f)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "data = data_f + data_n\n",
    "print(\"LEN DATA\")\n",
    "print(len(data))\n",
    "print(\"LEN DATA[0]\")\n",
    "print(len(data[0]))\n",
    "print(\"LEN COntainer\")\n",
    "for i in range(len(data[0])):\n",
    "    print(len(data[0][i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8f3cbcd2-eb0e-457b-b396-88c10368f5d2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#print(data[0][-1])\n",
    "#print(data[0])\n",
    "#print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "7b8bd1eb-72a0-4923-9fcd-c7f2630a4db8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def flatten(arr):\n",
    "    flattened = []\n",
    "    for element in arr:\n",
    "        if isinstance(element, list):\n",
    "            flattened.extend(flatten(element))\n",
    "        else:\n",
    "            flattened.append(element)\n",
    "    return flattened\n",
    "\n",
    "def nettoyage(dat):\n",
    "    for i in range(len(dat)):\n",
    "        dat[i].pop(0)\n",
    "        dat[i][-1] = flatten(dat[i][-1])\n",
    "        dat[i][-2] = flatten(dat[i][-2])\n",
    "    return dat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "58aa9c42-e7cf-464f-a13a-c7a4155ed81d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#print(nettoyage(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "78d29192-dc23-4c3a-9575-9abeb344c7c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LEN DATA\n",
      "1090\n",
      "LEN DATA[0]\n",
      "42\n",
      "LEN COntainer\n",
      "120\n",
      "3840\n",
      "3840\n",
      "120\n",
      "480\n",
      "120\n",
      "120\n",
      "7680\n",
      "3840\n",
      "120\n",
      "3840\n",
      "120\n",
      "3840\n",
      "7680\n",
      "120\n",
      "120\n",
      "480\n",
      "120\n",
      "3840\n",
      "120\n",
      "3840\n",
      "120\n",
      "480\n",
      "120\n",
      "120\n",
      "3840\n",
      "7680\n",
      "120\n",
      "3840\n",
      "120\n",
      "480\n",
      "7680\n",
      "3840\n",
      "120\n",
      "3840\n",
      "120\n",
      "3840\n",
      "120\n",
      "120\n",
      "120\n",
      "1\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "data = nettoyage(data)\n",
    "print(\"LEN DATA\")\n",
    "print(len(data))\n",
    "print(\"LEN DATA[0]\")\n",
    "print(len(data[0]))\n",
    "print(\"LEN COntainer\")\n",
    "for i in range(len(data[0])):\n",
    "    print(len(data[0][i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8694ae8-13b2-4d71-9634-cef62369d5b4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
